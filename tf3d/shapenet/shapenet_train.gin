num_classes = 4

# Preprocessor
semantic_pointcloud_preprocess.points_pad_or_clip_size = 3000
semantic_pointcloud_preprocess.point_feature_keys = ('point_offset_bins',)
semantic_pointcloud_preprocess.voxel_grid_cell_size = (0.00001, 0.00001, 0.00001)
semantic_pointcloud_preprocess.voxels_pad_or_clip_size = 3000
semantic_pointcloud_preprocess.z_min_degree_rotation = -180.0
semantic_pointcloud_preprocess.z_max_degree_rotation = 180.0
semantic_pointcloud_preprocess.points_key = 'pointcloud/position'
semantic_pointcloud_preprocess.intensities_key = None
semantic_pointcloud_preprocess.elongations_key = None
semantic_pointcloud_preprocess.colors_key = None
semantic_pointcloud_preprocess.normals_key = None
semantic_pointcloud_preprocess.motion_labels_key = None
semantic_pointcloud_preprocess.semantic_labels_key = 'pointcloud/label'
semantic_pointcloud_preprocess.spin_coords_key = None
semantic_pointcloud_preprocess.semantic_labels_offset = 0
semantic_pointcloud_preprocess.view_names = ('rgb_view',)
semantic_pointcloud_preprocess.points_in_image_frame_key = None
semantic_pointcloud_preprocess.ignore_labels = (255,)
semantic_pointcloud_preprocess.only_keep_first_return_lidar_points = False
semantic_pointcloud_preprocess.is_training = False


# Dataset
# get_tf_data_dataset.split_name = 'train'
get_tf_data_dataset.preprocess_fn = @semantic_pointcloud_preprocess
# get_tf_data_dataset.preprocess_fn = None
get_tf_data_dataset.feature_keys = ('voxel_features',
                                    'voxel_xyz_indices',
                                    'num_valid_voxels',
                                    'voxel_loss_weights')
get_tf_data_dataset.label_keys = ('object_class_voxels',)
get_tf_data_dataset.shuffle_buffer_size = 32
get_tf_data_dataset.filenames_shuffle_buffer_size = 100
get_tf_data_dataset.read_block_length = 2
get_tf_data_dataset.num_readers = 16


# 3D Network
SparseConvUNet.conv_filter_size = 3
# SparseConvUNet.encoder_dimensions = ((24, 24), (24, 32), (32, 48), (48, 64), (64, 80), (80, 96), (96, 112))
SparseConvUNet.encoder_dimensions = ((6, 6), (6, 8), (8, 12), (12, 16), (16, 20), (20, 24), (24, 28))
SparseConvUNet.bottleneck_dimensions = (28, 28)
# SparseConvUNet.decoder_dimensions = ((112, 112), (96, 96), (80, 80), (64, 64), (48, 48), (32, 32), (16, 16))
SparseConvUNet.decoder_dimensions = ((28, 28), (24, 24), (20, 20), (16, 16), (12, 12), (8, 8), (4, 4))
SparseConvUNet.use_batch_norm = True
SemanticSegmentationModel.num_classes = %num_classes


# Training
step_decay.boundary_list = [5000, 6000, 6500, 7000, 7500]
step_decay.ratio_list = [1.0, 0.3, 0.1, 0.03, 0.01, 0.001]
step_decay.initial_learning_rate = 0.01

train.learning_rate_fn = @step_decay
train.input_fn = @get_tf_data_dataset
# train.input_fn = @preprocess_data
train.optimizer_fn = @tf.keras.optimizers.SGD
train.model_class = @SemanticSegmentationModel
