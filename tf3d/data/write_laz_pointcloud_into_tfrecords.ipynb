{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec4a264",
   "metadata": {},
   "source": [
    "In this example we first read a .laz pointcloud file with pylas, then write a .tfrecords file accordingly. We start with importing all required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b98f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pylas\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbad17",
   "metadata": {},
   "source": [
    "Load the .laz point cloud file \"Point Clouds/Terrain with Buildings LiDAR.laz\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05df1de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points from Header: 625575\n",
      "<LasData(1.2, point fmt: <PointFormat(1)>, 625575 points, 0 vlrs)>\n",
      "Points from data: 625575\n"
     ]
    }
   ],
   "source": [
    "filename = \"Point Clouds/Terrain with Buildings LiDAR.laz\"\n",
    "\n",
    "with pylas.open(filename) as fh:\n",
    "    print('Points from Header:', fh.header.point_count)\n",
    "    las = fh.read()\n",
    "    print(las)\n",
    "    print('Points from data:', len(las.points))\n",
    "#     ground_pts = las.classification == 2\n",
    "#     bins, counts = np.unique(las.return_number[ground_pts], return_counts=True)\n",
    "#     print('Ground Point Return Number distribution:')\n",
    "#     for r,c in zip(bins,counts):\n",
    "#         print('    {}:{}'.format(r,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452c1ce",
   "metadata": {},
   "source": [
    "The point cloud file contains 625575 points, all stored in pointformat 1. For details of different pointformats, see https://pylas.readthedocs.io/en/latest/intro.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f9c49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'synthetic', 'key_point', 'withheld', 'scan_angle_rank', 'user_data', 'point_source_id', 'gps_time']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "lis = list(las.point_format.dimension_names)\n",
    "extralis = list(las.point_format.extra_dimension_names)\n",
    "print(lis)\n",
    "print(extralis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d0f8c5",
   "metadata": {},
   "source": [
    "The point cloud data dimension names. There are no extra dimension names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c857eb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 6]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(las.classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520097e8",
   "metadata": {},
   "source": [
    "We define _float_feature() and _int64_feature() to pack list of float or integer into tensorflow features. \n",
    "Code is from: https://www.tensorflow.org/tutorials/load_data/tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179fcf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc599b",
   "metadata": {},
   "source": [
    "Select the point cloud feature we need and make them a dictionary with proper key names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfb72885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"pointcloud/intensity\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 72\n",
      "        value: 88\n",
      "        value: 104\n",
      "        value: 88\n",
      "        value: 97\n",
      "        value: 79\n",
      "        value: 79\n",
      "        value: 94\n",
      "        value: 59\n",
      "        value: 103\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with features that may be relevant.\n",
    "def pointcloud2tfrecords(las):\n",
    "  \n",
    "    position, intensity, user_data, point_source_id, gps_time = [],[],[],[],[]\n",
    "    \n",
    "    for p in las.points:\n",
    "        \n",
    "        position.append(p['X'])\n",
    "        position.append(p['Y'])\n",
    "        position.append(p['Z'])\n",
    "        intensity.append(p['intensity'])\n",
    "        user_data.append(p['user_data'])\n",
    "        point_source_id.append(p['point_source_id'])\n",
    "#         gps_time.append(p['gps_time'])\n",
    "    \n",
    "\n",
    "    feature = {\n",
    "      'pointcloud/position': _int64_feature(position),\n",
    "      'pointcloud/intensity': _int64_feature(intensity),\n",
    "      'pointcloud/user_data': _int64_feature(user_data),\n",
    "      'pointcloud/point_source_id': _int64_feature(point_source_id),\n",
    "#       'pointcloud/gps_time': _float_feature(gps_time),\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "for line in str(pointcloud2tfrecords(las)).split('\\n')[:15]:\n",
    "    print(line)\n",
    "print('...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe85a62",
   "metadata": {},
   "source": [
    "Write it into a .tfrecords file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab56ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the point cloud to `Terrain with Buildings LiDAR.tfrecords`.\n",
    "# First, process the point cloud .laz file into `tf.train.Example` messages.\n",
    "# Then, write to a `.tfrecords` file.\n",
    "record_file = 'Terrain with Buildings LiDAR.tfrecords'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    \n",
    "    tf_example = pointcloud2tfrecords(las)\n",
    "    writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a1d3c",
   "metadata": {},
   "source": [
    "You can now try reading the newly create .tfrecords file using the read_tfrecords.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aafb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
